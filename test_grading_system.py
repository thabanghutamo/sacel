"""
Test Advanced Grading System Implementation
Comprehensive testing for rubric-based grading, automated assessment, and peer reviews
"""

import sys
import os
from datetime import datetime, timedelta

# Add the project root to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))


def test_grading_system_basic():
    """Test basic grading system functionality"""
    print("\n=== Testing Advanced Grading System ===")
    
    try:
        # Test imports
        print("‚úì Testing imports...")
        from app.services.grading_service import (
            GradingService, GradingRubric, RubricCriteria,
            invalidate_grading_cache, export_grades_to_csv
        )
        from app.models import User, Assignment, Submission
        print("  - All grading imports successful")
        
        # Test rubric creation
        print("‚úì Testing rubric system...")
        default_rubrics = GradingService.create_default_rubrics()
        assert 'essay' in default_rubrics
        assert 'mathematics' in default_rubrics
        print(f"  - Default rubrics created: {list(default_rubrics.keys())}")
        
        # Test rubric structure
        essay_rubric = default_rubrics['essay']
        assert essay_rubric.title == "Essay Writing Rubric"
        assert len(essay_rubric.criteria) == 5
        assert essay_rubric.total_points == 100
        print(f"  - Essay rubric: {essay_rubric.total_points} total points, {len(essay_rubric.criteria)} criteria")
        
        math_rubric = default_rubrics['mathematics']
        assert math_rubric.title == "Mathematics Problem Solving Rubric"
        assert len(math_rubric.criteria) == 4
        assert math_rubric.total_points == 100
        print(f"  - Math rubric: {math_rubric.total_points} total points, {len(math_rubric.criteria)} criteria")
        
        # Test criteria structure
        print("‚úì Testing criteria structure...")
        first_criteria = essay_rubric.criteria[0]
        assert hasattr(first_criteria, 'name')
        assert hasattr(first_criteria, 'description')
        assert hasattr(first_criteria, 'points')
        assert hasattr(first_criteria, 'performance_levels')
        
        performance_levels = first_criteria.performance_levels
        expected_levels = ['excellent', 'good', 'satisfactory', 'needs_improvement']
        for level in expected_levels:
            assert level in performance_levels
            assert 'description' in performance_levels[level]
            assert 'points_range' in performance_levels[level]
        print("  - Criteria structure validated")
        
        # Test utility functions
        print("‚úì Testing utility functions...")
        assert callable(invalidate_grading_cache)
        assert callable(export_grades_to_csv)
        print("  - Utility functions verified")
        
        print("\n‚úÖ Advanced Grading System Implementation Successful!")
        
        print("\nüéØ Grading Features Implemented:")
        print("  - Rubric-based assessment system")
        print("  - AI-powered automated grading")
        print("  - Peer review functionality")
        print("  - Performance level evaluation")
        print("  - Detailed feedback generation")
        print("  - Grade calculation and reporting")
        print("  - Cache management")
        print("  - CSV export capabilities")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import Error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Test Error: {e}")
        return False


def test_grading_api():
    """Test grading API endpoints"""
    print("\n=== Testing Grading API ===")
    
    try:
        from app.api.grading import grading_bp
        print("‚úì Grading API blueprint imported successfully")
        
        # Check blueprint properties
        assert grading_bp.name == 'grading'
        print("‚úì Blueprint name verified")
        
        print("‚úÖ Grading API ready for registration")
        
        print("\nüöÄ API Endpoints Available:")
        print("  - GET/POST /api/grading/rubrics - Rubric management")
        print("  - POST /api/grading/auto-grade/<id> - Automated grading")
        print("  - GET/POST /api/grading/peer-review/<id> - Peer reviews")
        print("  - POST /api/grading/peer-review/submit/<id> - Submit reviews")
        print("  - GET /api/grading/report/<id> - Grade reports")
        print("  - DELETE /api/grading/cache - Cache management")
        print("  - GET /api/grading/export/<id> - Grade export")
        print("  - GET /api/grading/dashboard - Grading dashboard")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå API Import Error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå API Test Error: {e}")
        return False


def test_grading_templates():
    """Test grading template files"""
    print("\n=== Testing Grading Templates ===")
    
    try:
        template_path = "app/templates/grading"
        
        # Check if template directory exists
        if os.path.exists(template_path):
            print(f"‚úì Template directory exists: {template_path}")
            
            # Check for specific template files
            expected_templates = [
                "teacher_dashboard.html"
            ]
            
            for template in expected_templates:
                template_file = os.path.join(template_path, template)
                if os.path.exists(template_file):
                    print(f"‚úì Template found: {template}")
                else:
                    print(f"‚ö†Ô∏è  Template missing: {template}")
            
            print("‚úÖ Grading templates structure verified")
            return True
        else:
            print(f"‚ùå Template directory not found: {template_path}")
            return False
            
    except Exception as e:
        print(f"‚ùå Template Test Error: {e}")
        return False


def test_rubric_performance_levels():
    """Test detailed rubric performance levels"""
    print("\n=== Testing Rubric Performance Levels ===")
    
    try:
        from app.services.grading_service import GradingService
        
        default_rubrics = GradingService.create_default_rubrics()
        essay_rubric = default_rubrics['essay']
        
        # Test each criteria has proper performance levels
        for criteria in essay_rubric.criteria:
            print(f"‚úì Testing criteria: {criteria.name}")
            
            # Verify point ranges are logical
            levels = criteria.performance_levels
            excellent_range = levels['excellent']['points_range']
            good_range = levels['good']['points_range']
            satisfactory_range = levels['satisfactory']['points_range']
            needs_improvement_range = levels['needs_improvement']['points_range']
            
            # Verify ranges don't overlap and are in descending order
            assert excellent_range[0] > good_range[1]
            assert good_range[0] > satisfactory_range[1]
            assert satisfactory_range[0] > needs_improvement_range[1]
            
            # Verify maximum points align
            assert excellent_range[1] == criteria.points
            
            print(f"  - Point ranges validated for {criteria.name}")
        
        print("‚úÖ All performance levels properly configured")
        return True
        
    except Exception as e:
        print(f"‚ùå Performance Level Test Error: {e}")
        return False


def test_ai_integration():
    """Test AI integration for grading"""
    print("\n=== Testing AI Integration ===")
    
    try:
        from app.services.ai_service import AIService
        print("‚úì AI service integration verified")
        
        # Test that grading service can use AI
        from app.services.grading_service import GradingService
        
        # Verify AI evaluation parsing methods exist
        assert hasattr(GradingService, '_parse_ai_evaluation')
        assert hasattr(GradingService, '_fallback_parse_evaluation')
        assert hasattr(GradingService, '_generate_overall_feedback')
        print("‚úì AI evaluation methods verified")
        
        print("‚úÖ AI integration ready for automated grading")
        return True
        
    except ImportError as e:
        print(f"‚ùå AI Integration Error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå AI Test Error: {e}")
        return False


def test_peer_review_system():
    """Test peer review functionality"""
    print("\n=== Testing Peer Review System ===")
    
    try:
        from app.services.grading_service import GradingService
        
        # Test peer review pairing method exists
        assert hasattr(GradingService, 'create_peer_review_assignment')
        assert hasattr(GradingService, '_create_peer_review_pairings')
        assert hasattr(GradingService, 'submit_peer_review')
        assert hasattr(GradingService, '_get_peer_review_scores')
        print("‚úì Peer review methods verified")
        
        # Test final grade calculation with peer reviews
        assert hasattr(GradingService, 'calculate_final_grade')
        print("‚úì Final grade calculation with peer reviews verified")
        
        print("‚úÖ Peer review system ready")
        return True
        
    except Exception as e:
        print(f"‚ùå Peer Review Test Error: {e}")
        return False


def test_grade_reporting():
    """Test grade reporting functionality"""
    print("\n=== Testing Grade Reporting ===")
    
    try:
        from app.services.grading_service import GradingService
        
        # Test report generation methods
        assert hasattr(GradingService, 'generate_grade_report')
        assert hasattr(GradingService, '_get_letter_grade')
        print("‚úì Grade reporting methods verified")
        
        # Test letter grade conversion
        assert GradingService._get_letter_grade(95) == 'A'
        assert GradingService._get_letter_grade(85) == 'B'
        assert GradingService._get_letter_grade(75) == 'C'
        assert GradingService._get_letter_grade(65) == 'D'
        assert GradingService._get_letter_grade(55) == 'F'
        print("‚úì Letter grade conversion verified")
        
        print("‚úÖ Grade reporting system ready")
        return True
        
    except Exception as e:
        print(f"‚ùå Grade Reporting Test Error: {e}")
        return False


def main():
    """Run all grading system tests"""
    print("üîç SACEL Advanced Grading System - Implementation Test")
    print("=" * 65)
    
    all_tests_passed = True
    
    # Run individual tests
    tests = [
        test_grading_system_basic,
        test_grading_api,
        test_grading_templates,
        test_rubric_performance_levels,
        test_ai_integration,
        test_peer_review_system,
        test_grade_reporting
    ]
    
    for test in tests:
        try:
            result = test()
            all_tests_passed = all_tests_passed and result
        except Exception as e:
            print(f"‚ùå Test {test.__name__} failed: {e}")
            all_tests_passed = False
    
    print("\n" + "=" * 65)
    
    if all_tests_passed:
        print("üéâ ALL GRADING SYSTEM TESTS PASSED!")
        print("\nüìä Advanced Grading System is ready for production!")
        
        print("\nüîß Next Steps:")
        print("1. Start the Flask development server")
        print("2. Navigate to /api/grading/dashboard")
        print("3. Test rubric creation and management")
        print("4. Try automated grading with AI")
        print("5. Setup peer review assignments")
        print("6. Generate comprehensive grade reports")
        
        print("\nüí° Usage Examples:")
        print("- Create custom rubrics for different subjects")
        print("- Auto-grade essay submissions with AI analysis")
        print("- Setup peer review cycles for collaborative learning")
        print("- Generate detailed feedback with performance insights")
        print("- Export grades to CSV for gradebook integration")
        
    else:
        print("‚ö†Ô∏è  Some tests failed. Please check the implementation.")
    
    return all_tests_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)